{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637ad4a9-e162-4bf9-ae5f-a7c95bd7bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched Article: Americans freed in Russia prisoner swap land in US - BBC.com US President Joe Biden welcomed them off the plane at Joint Base Andrews in Maryland.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_news_article(api_key):\n",
    "    url = f'https://newsapi.org/v2/top-headlines?country=us&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if data['status'] == 'ok' and data['articles']:\n",
    "        articles = data['articles']\n",
    "        for article in articles:\n",
    "            if article['title'] and article['description']:\n",
    "                return article['title'] + \" \" + article['description']\n",
    "    return None\n",
    "\n",
    "api_key = '249f32a912ef45098f9afeebb871c876'\n",
    "article = fetch_news_article(api_key)\n",
    "if article:\n",
    "    print(\"Fetched Article:\", article)\n",
    "else:\n",
    "    print(\"Failed to fetch an article. Please check your API key and network connection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b57cb2-9826-408f-a427-a286a7a514da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ebine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\ebine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ebine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Entities: [('Americans', 'GPE'), ('Russia', 'GPE'), ('US', 'GPE'), ('Joe Biden', 'PERSON'), ('Joint Base Andrews', 'ORGANIZATION'), ('Maryland', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "def nltk_ner(text):\n",
    "    words = word_tokenize(text)\n",
    "    tags = pos_tag(words)\n",
    "    tree = ne_chunk(tags)\n",
    "    entities = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, nltk.Tree):\n",
    "            entity = \" \".join([word for word, tag in subtree.leaves()])\n",
    "            entity_type = subtree.label()\n",
    "            entities.append((entity, entity_type))\n",
    "    return entities\n",
    "\n",
    "if article:\n",
    "    nltk_entities = nltk_ner(article)\n",
    "    print(\"NLTK Entities:\", nltk_entities)\n",
    "else:\n",
    "    print(\"No article to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39780ee-e482-495c-afda-87357f673346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy Entities: [('Americans', 'NORP'), ('Russia', 'GPE'), ('US', 'GPE'), ('US', 'GPE'), ('Joe Biden', 'PERSON'), ('Joint Base Andrews', 'FAC'), ('Maryland', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def spacy_ner(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "if article:\n",
    "    spacy_entities = spacy_ner(article)\n",
    "    print(\"SpaCy Entities:\", spacy_entities)\n",
    "else:\n",
    "    print(\"No article to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a8f0cb-cada-433e-a5d8-b86c32e7513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Entities: {('Maryland', 'GPE'), ('Joe Biden', 'PERSON'), ('US', 'GPE'), ('Russia', 'GPE')}\n",
      "Entities only in NLTK: {('Joint Base Andrews', 'ORGANIZATION'), ('Americans', 'GPE')}\n",
      "Entities only in SpaCy: {('Joint Base Andrews', 'FAC'), ('Americans', 'NORP')}\n"
     ]
    }
   ],
   "source": [
    "def compare_entities(nltk_entities, spacy_entities):\n",
    "    nltk_set = set(nltk_entities)\n",
    "    spacy_set = set(spacy_entities)\n",
    "    \n",
    "    common = nltk_set & spacy_set\n",
    "    only_nltk = nltk_set - spacy_set\n",
    "    only_spacy = spacy_set - nltk_set\n",
    "\n",
    "    return common, only_nltk, only_spacy\n",
    "\n",
    "if article:\n",
    "    common_entities, only_nltk_entities, only_spacy_entities = compare_entities(nltk_entities, spacy_entities)\n",
    "\n",
    "    print(\"Common Entities:\", common_entities)\n",
    "    print(\"Entities only in NLTK:\", only_nltk_entities)\n",
    "    print(\"Entities only in SpaCy:\", only_spacy_entities)\n",
    "else:\n",
    "    print(\"No entities to compare.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03b178-f3fe-4afa-be2e-c279e063a694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
